{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ive been feeling a little burdened lately wasn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion\n",
       "0      i can go from feeling so hopeless to so damned...  sadness\n",
       "1       im grabbing a minute to post i feel greedy wrong    anger\n",
       "2      i am ever feeling nostalgic about the fireplac...     love\n",
       "3                                   i am feeling grouchy    anger\n",
       "4      ive been feeling a little burdened lately wasn...  sadness\n",
       "...                                                  ...      ...\n",
       "15994  i just had a very brief time in the beanbag an...  sadness\n",
       "15995  i am now turning and i feel pathetic that i am...  sadness\n",
       "15996                     i feel strong and good overall      joy\n",
       "15997  i feel like this was such a rude comment and i...    anger\n",
       "15998  i know a lot but i feel so stupid because i ca...  sadness\n",
       "\n",
       "[15999 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer=PorterStemmer()\n",
    "data_frame = pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "\n",
    "df=data_frame.rename(columns={'i didnt feel humiliated':'text','sadness':'emotion'})\n",
    "df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"text\", \n",
    "                     keep = False, inplace = True) \n",
    "df.replace(\"[^a-zA-Z]\",\" \",regex=True,inplace=True)\n",
    "ind=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['index'],axis=1)\n",
    "Y = pd.get_dummies(df['emotion']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexx in ind:\n",
    "    df[indexx]=df[indexx].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df['text']\n",
    "corpus=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in text:\n",
    "    words=nltk.word_tokenize(i)\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    i=' '.join(words)\n",
    "    corpus.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding , LSTM\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.models import Sequential\n",
    "voc_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = [one_hot(words,voc_size) for words in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs= pad_sequences(onehot,padding='pre',maxlen=sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(embedded_docs)\n",
    "y_train=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 32s 88ms/step - loss: 1.5815 - accuracy: 0.3621\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 27s 106ms/step - loss: 0.8043 - accuracy: 0.7378\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3832 - accuracy: 0.8682\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 19s 76ms/step - loss: 0.2426 - accuracy: 0.9152\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 21s 86ms/step - loss: 0.1998 - accuracy: 0.9314\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.1541 - accuracy: 0.9447\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 24s 94ms/step - loss: 0.1268 - accuracy: 0.9532\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 23s 94ms/step - loss: 0.1063 - accuracy: 0.9595\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 22s 89ms/step - loss: 0.0993 - accuracy: 0.9651\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 24s 95ms/step - loss: 0.0846 - accuracy: 0.9715\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 24s 94ms/step - loss: 0.0766 - accuracy: 0.9716\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.0668 - accuracy: 0.9764\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.0628 - accuracy: 0.9782\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 19s 78ms/step - loss: 0.0597 - accuracy: 0.9771\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 20s 80ms/step - loss: 0.0506 - accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_length, input_length=x_train.shape[1]))\n",
    "\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame=pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "test_df=test_frame.rename(columns={'im feeling rather rotten so im not very ambitious right now':'text','sadness':'emotion'})\n",
    "\n",
    "test_df.dropna( )\n",
    "\n",
    "test_df.drop_duplicates(subset =\"text\", \n",
    "                     keep = False, inplace = True) \n",
    "\n",
    "test_df.replace(\"[^a-zA-Z]\",\" \",regex=True,inplace=True)\n",
    "\n",
    "test_ind=test_df.columns\n",
    "\n",
    "test_df=test_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=test_df.drop(['index'],axis=1)\n",
    "test_Y=pd.get_dummies(test_df['emotion']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexx in test_ind:\n",
    "    test_df[indexx]=test_df[indexx].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text=test_df['text']\n",
    "test_corpus=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_text:\n",
    "    words=nltk.word_tokenize(i)\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    i=' '.join(words)\n",
    "    test_corpus.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onehot=[one_hot(words,voc_size) for words in test_corpus]\n",
    "test_embedded_docs=pad_sequences(test_onehot,padding='pre',maxlen=sent_length)\n",
    "x_test=np.array(test_embedded_docs)\n",
    "y_test=np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_y=[]    \n",
    "for i in range(len(y_test)):\n",
    "    l=y_test[i].tolist()\n",
    "    final_y.append(l.index(max(l))) \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=[]    \n",
    "for i in range(len(predictions)):\n",
    "    l=predictions[i].tolist()\n",
    "    final_result.append(l.index(max(l))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8534267133566783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(final_y,final_result)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
